{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f7637c5",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26092d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing random forest regressor to predict the value of house\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(house_prepared, house_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc1c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to know the MSE and MAE of the model used \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "house_predicted = forest_reg.predict(house_prepared)\n",
    "forest_mse = mean_squared_error(house_labels, house_predicted)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print(\"RMSE ==> \", forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ec7dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    \n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impoting cross val score to cross validaton about the performance of the model tained\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forest_scores = cross_val_score(forest_reg, house_prepared, house_labels,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=5)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465523d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(house_prepared, house_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ead60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3409453",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# --- Save the Model ---\n",
    "# (You should already have this from the previous step)\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    # Replace 'grid_search.best_estimator_' with your final model variable if different\n",
    "    pickle.dump(final_model, f)\n",
    "\n",
    "# --- Save the Preprocessing Pipeline ---\n",
    "# The pipeline must be fitted on your training data before saving\n",
    "with open('preprocessing_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(full_pipeline, f)\n",
    "\n",
    "print(\"Model and pipeline have been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
